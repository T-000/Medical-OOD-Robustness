import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np

from create_dataloader import KITS23Dataset
from kits23_unet_fixed import KITS23UNetFixed


class MedicalViewer:
    def __init__(self):
        self.dataset = KITS23Dataset()
        self.current_case_idx = 0
        self.current_slice = 64  # ä¸­é—´åˆ‡ç‰‡
        self.window_center = 40   # CTçª—ä½
        self.window_width = 400   # CTçª—å®½
        self.model = None
        self.model_loaded = False

        self.ai_mask = None  # å­˜å‚¨AIé¢„æµ‹ç»“æœ
        self.has_ai_prediction = False  # æ ‡è®°æ˜¯å¦å·²é¢„æµ‹

        self.current_case_loaded = False  # æ ‡è®°å½“å‰ç—…ä¾‹æ˜¯å¦åŠ è½½
        self.image = None
        self.mask = None

    def load_case(self, case_idx):
        """åŠ è½½æŒ‡å®šç—…ä¾‹"""
        try:
            self.current_case_idx = case_idx
            self.image, self.mask = self.dataset[case_idx]
            self.image = self.image.squeeze().numpy()  # [128,512,512]
            self.mask = self.mask.squeeze().numpy()  # [128,512,512]
            self.current_case_loaded = True
            self.ai_mask = None  # é‡ç½®AIé¢„æµ‹
            print(f"âœ… æˆåŠŸåŠ è½½ç—…ä¾‹ {case_idx}")
            return self.get_case_info()
        except Exception as e:
            print(f"âŒ åŠ è½½ç—…ä¾‹å¤±è´¥: {e}")
            self.current_case_loaded = False
            return None

    def apply_ct_window(self, image):
        """åº”ç”¨CTçª—å®½çª—ä½"""
        min_val = self.window_center - self.window_width // 2
        max_val = self.window_center + self.window_width // 2
        windowed = np.clip(image, min_val, max_val)
        windowed_normalized = (windowed - min_val) / (max_val - min_val)
        return np.clip(windowed_normalized, 0, 1)  # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…

    def get_slice(self, slice_idx=None):
        """è·å–æŒ‡å®šåˆ‡ç‰‡"""
        if not self.current_case_loaded:
            print("âš ï¸  è¯·å…ˆåŠ è½½ç—…ä¾‹")
            return None, None

        if slice_idx is None:
            slice_idx = self.current_slice

        # ç¡®ä¿åˆ‡ç‰‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
        slice_idx = max(0, min(slice_idx, self.image.shape[0] - 1))
        self.current_slice = slice_idx

        ct_slice = self.apply_ct_window(self.image[slice_idx])
        mask_slice = self.mask[slice_idx]

        return ct_slice, mask_slice

    def get_case_info(self):
        """è·å–ç—…ä¾‹ä¿¡æ¯"""
        if not self.current_case_loaded:
            return {'name': 'No case loaded', 'shape': None, 'slices': 0}

        case_name = f"case_{self.current_case_idx:05d}"
        shape = self.image.shape
        return {
            'name': case_name,
            'shape': shape,
            'slices': shape[0]
        }

    def load_model(self, model_path='models/kits23_trained_model.pth'):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("ğŸ§  åŠ è½½AIåˆ†å‰²æ¨¡å‹...")
        try:
            self.model = KITS23UNetFixed()
            checkpoint = torch.load(model_path, map_location='cpu')
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            self.model_loaded = True
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            return True
        except FileNotFoundError:
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            # åˆ—å‡ºmodelsæ–‡ä»¶å¤¹å†…å®¹å¸®åŠ©è°ƒè¯•
            import os
            if os.path.exists('models'):
                print(f"ğŸ“ modelsæ–‡ä»¶å¤¹å†…å®¹: {os.listdir('models')}")
            return False
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def predict_case(self, image_tensor):
        """å¯¹ç—…ä¾‹è¿›è¡ŒAIé¢„æµ‹ - ä¿®å¤ç‰ˆæœ¬"""
        if not self.model_loaded:
            print("âš ï¸  è¯·å…ˆåŠ è½½æ¨¡å‹")
            return None

        if not self.current_case_loaded:
            print("âš ï¸  è¯·å…ˆåŠ è½½ç—…ä¾‹")
            return None

        try:
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
            print(f"   ğŸ“Š è¾“å…¥æ•°æ®èŒƒå›´: [{image_tensor.min():.3f}, {image_tensor.max():.3f}]")

            with torch.no_grad():
                image_tensor = image_tensor.float()
                output = self.model(image_tensor.unsqueeze(0))

                print(f"   ğŸ“Š æ¨¡å‹è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
                print(f"   ğŸ“Š æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")

                # ä¿®å¤ï¼šä½¿ç”¨softmaxå°†logitsè½¬æ¢ä¸ºæ¦‚ç‡
                probabilities = F.softmax(output, dim=1)
                print(f"   ğŸ“Š SoftmaxåèŒƒå›´: [{probabilities.min():.3f}, {probabilities.max():.3f}]")
                prediction = torch.argmax(probabilities, dim=1).squeeze(0)
                print(f"   ğŸ“Š åŸå§‹é¢„æµ‹ç±»åˆ«: {torch.unique(prediction)}")

                # å°†ç±»åˆ«3æ˜ å°„ä¸ºèƒŒæ™¯
                prediction = torch.where(prediction == 3, torch.tensor(0), prediction)

                # ç»Ÿè®¡é¢„æµ‹ç»“æœ
                unique, counts = torch.unique(prediction, return_counts=True)
                class_distribution = dict(zip(unique.numpy(), counts.numpy()))
                print(f"   ğŸ“Š é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ: {class_distribution}")

                return prediction.numpy()

        except Exception as e:
            print(f"âŒ AIé¢„æµ‹å¤±è´¥: {e}")
            return None

    def predict_entire_case(self):
        """å¯¹æ•´ä¸ªç—…ä¾‹è¿›è¡ŒAIé¢„æµ‹ï¼ˆåªè°ƒç”¨ä¸€æ¬¡ï¼‰"""
        if not self.model_loaded or not self.current_case_loaded:
            return False

        if self.has_ai_prediction and self.ai_mask is not None:
            return True  # å·²ç»é¢„æµ‹è¿‡äº†

        print("ğŸ¤– è¿è¡ŒAIåˆ†å‰²...")
        image_tensor = torch.from_numpy(self.image).unsqueeze(0).float()
        self.ai_mask = self.predict_case(image_tensor)

        if self.ai_mask is not None:
            self.has_ai_prediction = True
            print("âœ… AIé¢„æµ‹å®Œæˆ")
            return True
        else:
            print("âŒ AIé¢„æµ‹å¤±è´¥")
            return False

    def run_ai_prediction(self):
        """æ˜¾å¼è¿è¡ŒAIé¢„æµ‹ - ç”¨æˆ·æ˜ç¡®çŸ¥é“è¿™æ˜¯åœ¨æ‰§è¡Œè€—æ—¶æ“ä½œ"""
        if not self.model_loaded:
            print("âš ï¸  è¯·å…ˆåŠ è½½æ¨¡å‹")
            return False

        if not self.current_case_loaded:
            print("âš ï¸  è¯·å…ˆåŠ è½½ç—…ä¾‹")
            return False

        if self.has_ai_prediction:
            print("â„¹ï¸  å·²ç»è¿è¡Œè¿‡AIé¢„æµ‹")
            return True

        print("ğŸ¤– è¿è¡ŒAIåˆ†å‰²...")
        try:
            image_tensor = torch.from_numpy(self.image).unsqueeze(0).float()
            self.ai_mask = self.predict_case(image_tensor)

            if self.ai_mask is not None:
                self.has_ai_prediction = True
                print("âœ… AIé¢„æµ‹å®Œæˆ")
                return True
            else:
                print("âŒ AIé¢„æµ‹å¤±è´¥")
                return False
        except Exception as e:
            print(f"âŒ AIé¢„æµ‹å¼‚å¸¸: {e}")
            return False

    def get_ai_prediction(self, slice_idx=None):
        """åªè·å–AIé¢„æµ‹çš„åˆ‡ç‰‡ï¼Œç»å¯¹ä¸è§¦å‘é¢„æµ‹"""
        if slice_idx is None:
            slice_idx = self.current_slice

        # ç®€å•çš„æ•°æ®è·å–ï¼Œæ²¡æœ‰å‰¯ä½œç”¨
        if not self.has_ai_prediction or self.ai_mask is None:
            return None

        if 0 <= slice_idx < self.ai_mask.shape[0]:
            return self.ai_mask[slice_idx]
        else:
            print(f"âš ï¸  åˆ‡ç‰‡ç´¢å¼•è¶…å‡ºèŒƒå›´: {slice_idx}")
            return None

    def clear_ai_prediction(self):
        """æ¸…é™¤å½“å‰çš„AIé¢„æµ‹"""
        self.ai_mask = None
        print("ğŸ§¹ å·²æ¸…é™¤AIé¢„æµ‹ç»“æœ")
